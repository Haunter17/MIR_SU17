# Benchmark Tools for Representations

## Overview
The purpose of this set of benchmark tools is to help analyze the performace of different representations on the live song ID task. This mini benchmark has two advantages:

* It takes much less time to run than the MRR benchmark
* It gives much more detailed information about how representation handles different types of distortions


There are three major scripts for running the tool:

* [benchmarkDriver.m](https://github.com/Haunter17/MIR_SU17/blob/master/exp7/benchmark/benchmarkDriver.m)
* [statPlot.py](https://github.com/Haunter17/MIR_SU17/blob/master/exp7/benchmark/statPlot.py)
* [matchPctPlot.py](https://github.com/Haunter17/MIR_SU17/blob/master/exp7/benchmark/matchPctPlot.py)

## Calling the benchmark driver
To evaluate a representation, you first learn a model and save it to file before calling the driver. Given the model file, the driver computes the representation on an arbitrarily chosen song with the clean album track and different distorted versions. Next, it generates a report that contains

* correlation statistics for each bit in the representation for the clean album track
* percentage of ones for each bit in the representation for the clean album track
* correlation statistics across different bits in the representation for the clean album track
* percentage of bits that match between each distorted and the clean version

The benchmark driver will request the following user input:

1. Flag number for the representation (1 = hashprint, 2 = randomized, 3 = AE ...)

2. Name of the model file to read (without including ".mat")

3. Name of the output file to dump the report (without including ".out")


For instance, to call the autoencoder representation with the model file `AE_relu.mat` and output file `AE_relu_test.out`, the combination of user input will be "3, AE_relu, AE_relu_test".

Besides generating the `.out` verbose report, this driver also generates a `.mat` file with the same name as the verbose output file. This `.mat` file stores the data for the benchmark performance.

## Plotting correlation and bit statistics
The python script [statPlot.py](https://github.com/Haunter17/MIR_SU17/blob/master/exp7/benchmark/statPlot.py) helps visualize the bit correlation and percentage statistics. Enter the following command in terminal to generate plots for the statistics:

```
  python3 statPlot.py <path_to_mat_file>
```

where the `<path_to_mat_file>` corresponds to the `.mat` file generated by the benchmark driver. The script will automatically generate two figures under the same directory as the python script.

An example call to the script is shown as following:

```
  python3 statPlot.py AE_test.mat
```

## Plotting bit matching statistics
The python script [matchPctPlot.py](https://github.com/Haunter17/MIR_SU17/blob/master/exp7/benchmark/matchPctPlot.py) helps visualize the bit matching statistics between the clean and different distorted versions. Enter the following command in terminal to generate plots for bit matching:

```
  python3 matchPctPlot.py <number_of_representations> <list_of_representation_names>
  <path_to_mat_file1> <path_to_mat_file2> ...
```
where
*  `<number_of_representations>` is the number of different representations to include in the plot
* `<list_of_representation_names>` is the list of the names for the representations
* `<path_to_mat_file1> <path_to_mat_file2> ... ` refers to the `.mat` file generated by the benchmark driver

Notice that 
* The list of names have to be passed in as string, in which each element is separated by a comma
* the order of the `.mat` files has to be consistent with the order of the names passed into `<list_of_representation_names>`

For example, we can compare three different representations with

```
  python3 matchPctPlot.py 3 'hashprint, randomized, AE' hashprint.mat randomized.mat AE.mat
```

## Notes for Developers
### Adding more representations
TODO
